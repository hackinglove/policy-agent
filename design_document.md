# 数字经济政策自动采集与即时推送系统 - 设计文档

## 1. 项目概述
本项目旨在开发一个自动化 Python 脚本，用于每日定时从指定的政府官方网站（国家级及重点省市）采集关于“数字经济”领域的最新政策。系统将自动筛选昨日发布的政策，利用 AI 进行摘要生成，并在每日上午 9:00 通过微信推送给用户。

## 2. 核心功能需求
*   **采集范围**：
    *   **关键词**：数字经济、算力基础设施、数实融合、实体经济发展。
    *   **行政级别**：国家级（发改委、工信部、科技部、数据局）；省级（北京、上海、江苏、浙江、广东）；重点市级（上述省份的省会或数字经济发达城市）。
*   **数据筛选**：仅抓取“昨日”发布的数据，确保时效性。
*   **智能处理**：生成 100-200 字的政策核心概括（AI 摘要为可选配置，未配置时截取正文）。
*   **定时推送**：每天上午 09:00 推送。
*   **推送渠道**：同时支持 PushPlus 和 Webhook（如企业微信/钉钉/飞书机器人）。
*   **内容格式**：序号、政策名、发文单位、发布时间、摘要、跳转链接。

## 3. 系统架构设计

系统由四个核心模块组成：

```mermaid
graph TD
    A[定时调度器 (Scheduler)] -->|每天 09:00| B[爬虫控制器 (Crawler Manager)]
    B --> C1[国家部委抓取器]
    B --> C2[重点省市抓取器]
    C1 --> D[数据清洗 & 去重 (Filter)]
    C2 --> D
    D --> E[AI 摘要生成器 (Summarizer)]
    E --> F[SQLite 数据库 (Storage)]
    F --> G[消息格式化 (Formatter)]
    G --> H[微信推送服务 (Notifier)]
```

## 4. 详细模块设计

### 4.1 数据源配置 (Configuration)
我们将维护一个目标 URL 列表（`sources.json`），便于后期维护扩展：
*   **国家级**：
    *   国家发改委 - 高技术司/政策发布栏目
    *   工信部 - 政策法规/文件发布
    *   国家数据局 - 政策发布
    *   科技部 - 政策法规
*   **地方级**：
    *   北京市经信局/发改委
    *   上海市经信委/发改委
    *   江苏省工信厅/发改委
    *   浙江省经信厅/发改委
    *   广东省工信厅/发改委/政务服务和数据管理局
    *   (可扩展) 杭州、南京、苏州、深圳、广州等重点城市相关部门。

### 4.2 爬虫模块 (Crawler)
考虑到政府网站可能存在反爬策略或动态加载（JavaScript），技术选型如下：
*   **核心库**：`Playwright` (处理动态渲染) 或 `Requests` + `BeautifulSoup` (处理静态页面)。
*   **逻辑**：
    1.  遍历 URL 列表。
    2.  提取文章列表中的 **标题** 和 **日期**。
    3.  **初筛**：判断日期是否为“昨天”。
    4.  **关键词匹配**：检查标题或正文是否包含配置的关键词（数字经济、算力等）。
    5.  **详情抓取**：进入详情页获取正文内容。

### 4.3 数据处理与 AI 摘要 (Processor)
*   **去重**：使用 URL 或 “标题+发文单位” 作为唯一键，存入 SQLite 防止重复推送。
*   **摘要生成**：
    *   调用大模型 API（如 DeepSeek, ChatGPT, 通义千问等）。
    *   **Prompt 设计**：“请阅读以下政策文件内容，生成 100-200 字的概括，重点突出对企业的利好、核心指标或执行标准。”

系统将同时支持以下两种推送方式，用户可在配置中开启一种或多种：
1.  **PushPlus (推送加)**：通过公众号接收消息，适合个人用户。
2.  **Webhook 机器人**：支持企业微信、钉钉、飞书的群机器人 Webhook 地址。

由于个人微信接口受限，推荐使用 **PushPlus (推送加)** 或 **企业微信群机器人**。
*   **消息模板**：
    ```text
    📅 【数字经济政策日报】 202x-xx-xx
    
    1. 《关于加快建设算力基础设施的指导意见》
    🏢 单位：工业和信息化部
    ⏰ 时间：202x-xx-xx
    📝 概括：(AI生成的100字摘要...)
    🔗 链接：[点击查看详情](http://...)
    ------------------------------
    2. ...
    ```

## 5. 技术栈选择
*   **语言**：Python 3.9+
*   **爬虫**：`playwright`, `lxml`
*   **调度**：`apscheduler` (用于脚本内定时) 或 系统级 Crontab
*   **摘要**：OpenAI SDK (兼容各大模型接口)
*   **数据库**：`sqlite3` (轻量级，无需安装服务)

## 6. 开发与测试计划
1.  **阶段一**：编写通用爬虫类，测试抓取工信部和北京市经信局网站（验证反爬和解析）。
2.  **阶段二**：接入 AI 摘要接口，调试 Prompt 效果。
3.  **阶段三**：实现数据去重和定时任务逻辑。
4.  **阶段四**：配置微信推送，进行全流程模拟测试。

## 7. 给用户的确认事项
在开始编程前，请确认以下几点：
1.  **摘要接口**：您是否有偏好的 LLM API Key（如 OpenAI, DeepSeek, 阿里通义等）？如果没有，可以直接使用免费的提取摘要算法并在本地运行，或者需要您提供一个 Key。
2.  **运行环境**：脚本是运行在您的本地电脑（需保持开机）还是云服务器上？
3.  **推送渠道**：您是否接受使用 PushPlus（需关注公众号获取 Token）作为推送方式？这是目前最稳定且免费的个人推送方案。
